{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4d914934-0000-43ab-87ea-83eb5d71d382",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import speech\n",
    "from google.cloud import storage\n",
    "from google.protobuf.json_format import MessageToDict\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fa9714da-25ce-4a57-afb6-94d316c1a69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_medical_wav(wav_file_path):\n",
    "    \"\"\"\n",
    "    Transcribe a medical WAV file using Google Speech-to-Text API.\n",
    "\n",
    "    Args:\n",
    "        wav_file_path (str): The path to the WAV file to be transcribed.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of tuples containing the transcript and confidence score.\n",
    "    \"\"\"\n",
    "    client = speech.SpeechClient()\n",
    "\n",
    "    # Load the audio file\n",
    "    with io.open(wav_file_path, \"rb\") as audio_file:\n",
    "        content = audio_file.read()\n",
    "\n",
    "    audio = speech.RecognitionAudio(content=content)\n",
    "\n",
    "    # Specify that the audio data is medical audio\n",
    "    config = speech.RecognitionConfig(\n",
    "        encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "        sample_rate_hertz=44100,  # Sample rate of your WAV file\n",
    "        language_code=\"en-US\",  # Language code\n",
    "        audio_channel_count=1,\n",
    "        enable_separate_recognition_per_channel=False,\n",
    "        use_enhanced=True,\n",
    "        model=\"video\",  # Use the medical model\n",
    "        enable_automatic_punctuation=True,\n",
    "        diarization_config=None\n",
    "    )\n",
    "\n",
    "    # Perform the transcription\n",
    "    response = client.recognize(config=config, audio=audio)\n",
    "\n",
    "    # Output the transcripts\n",
    "    transcripts = []\n",
    "    for result in response.results:\n",
    "        transcript = result.alternatives[0].transcript\n",
    "        confidence = result.alternatives[0].confidence\n",
    "        transcripts.append((transcript, confidence))\n",
    "\n",
    "    return transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4322a354-eadc-42f0-94ea-00f2cec87a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_with_beeps = 'test-s2t-models/Nursing Assessment Audio with Beep/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c3e73e4f-d1fe-40d9-b1d0-97ac5a055c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_with_beeps = 'test-s2t-models/Nursing Assessment Recordings no beep/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3a3be1a8-cf52-4eef-9216-4fdb8f3f763f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def transcribe_all_wav_files_in_directory(directory_path):\n",
    "    \"\"\"\n",
    "    Transcribe all WAV files in a directory using Google Speech-to-Text API.\n",
    "\n",
    "    Args:\n",
    "        directory_path (str): The path to the directory containing WAV files.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of tuples where each tuple contains the WAV file name and its transcripts.\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557a04ae-eb6e-4b8b-8e1b-e208d41658eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
